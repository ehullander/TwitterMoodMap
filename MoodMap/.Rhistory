cacheSolve(blob)
## These are a pair of functions that cache
## the inverse of a matrix.
## Function creates a list of functions
## which will be used to store the inverse.
makeCacheMatrix <- function(x = matrix()) {
#Matrix to store inverse matrix
inv <- NULL
#Function-substitutes matrix x with matrix y in main function
set <- function(y){
x <<- y
#sets old inverse matrix to null
inv <<- NULL
}
#Function-Retrieves the matrix given by main function
get <- function() x
#Function-stores value of the inverse into the main function
setinverse <- function(inverse) inv <<- inverse
#Function-Retrieves inverse matrix
getinverse <- function() inv
#List of the 4 functions
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
## Function computes the inverse of the matrix
## formed by makeCacheMatrix. First checks if
## the inverse has already been computed and
## computes inverse if it has not.
cacheSolve <- function(x, ...) {
inv <- x$getinverse()
#checking if inverse is already computed
if(!is.null(inv)){
message("getting cached data")
return(inv)
}
#if no inverse, gets matrix and computes inverse
data <- x$get()
inv <- solve(data,...)
#stores inverse in makeCacheMatrix
x$setinverse(inv)
inv
}
blob=makeCacheMatrix(test)
cacheSolve(blob)
cacheSolve(blob)
data(airquality)
str(airquality)
?split
split(airquality,airquality$Month)
s=split(airquality,airquality$Month)
str(s)
?scale
require(stats)
x <- matrix(1:10, ncol = 2)
(centered.x <- scale(x, scale = FALSE))
cov(centered.scaled.x <- scale(x)) # all 1
x
?cov
swirl
swirl()
library(swirl)
ls()
rm(list=ls())
?rpois
set.seed(1)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
set.seed(2)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
?rnorm
set.seed(10)
x <- rep(0:1, each = 5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
plot(x,y)
plot(y,x)
?is
is(x,int)
is(x,numeric)
is(x)
is.na(x)
is.numeric(x)
?numeric
?factor
?str
summary(x)
str(x)
ls()
?rm
rm(ls())
list=ls()
rm(list)
rm(list=ls())
rm
?.Primitive
list <- .Primitive("c")(list, names)
list
?character
characer(a)
character(a)
character('a')
character("a")
characer(1)
character(1)
3
library("installr", lib.loc="~/R/win-library/3.2")
updateR()
library(ROAuth)
library(streamR)
library(RJSONIO)
library(RMySQL)
library(ggplot2)
library(dplyr)
con <- dbConnect(MySQL(),
user = 'ehullander',
password = 'plazmajaz',
host = 'mydbehullander.c2hqmnrywoe9.us-west-2.rds.amazonaws.com',
dbname='TwitterStream')
con <- dbConnect(MySQL(),
user = 'ehullander',
password = 'plazmajaz',
host = 'mydbehullander.c2hqmnrywoe9.us-west-2.rds.amazonaws.com',
dbname='TwitterStream')
dbDisconnect(con)
con <- dbConnect(MySQL(),
user = 'ehullander',
password = 'plazmajaz',
host = 'mydbehullander.c2hqmnrywoe9.us-west-2.rds.amazonaws.com',
dbname='TwitterStream')
dbDisconnect(con)
library(ROAuth)
library(streamR)
library(RJSONIO)
library(RMySQL)
library(ggplot2)
library(dplyr)
if(!file.exists('myEnvironment.RData'))
{
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "http://api.twitter.com/oauth/authorize"
consumerKey <- "8awxQDQEoJJzeRC6QGoCwnyqz"
consumerSecret <- "phgdvkUSZ6T1WSHF2XIwjrSvSGVdtRlqUkTOxwtMaPwKLGdedA"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
save.image("myEnvironment.RData")
} else {load('myEnvironment.RData')}
tweets<-data.frame()
temp<-filterStream(file="",
locations=c(-125.0011, 24.9493, -66.9326, 49.5904),
timeout=60,
oauth=my_oauth)
j=0
L=length(temp)
for (i in 1:L)
{
if (isValidJSON(I(temp[i]))==TRUE)
{
j=j+1
JSON<-fromJSON(temp[i])
if(!is.null(JSON$text)&!is.null(JSON$place$full_name))
{
tweets[j,1]<-JSON$id_str
tweets[j,2]<-JSON$user$screen_name
tweets[j,3]<-as.character(strptime(paste(substr(JSON$created_at, 5,10),
substr(JSON$created_at, 27,30),
substr(JSON$created_at, 12,19)),
"%b %d %Y %H:%M:%S"))
tweets[j,4]<-JSON$place$bounding_box$coordinates[[1]][[1]][2]
tweets[j,5]<-JSON$place$bounding_box$coordinates[[1]][[1]][1]
tweets[j,6]<-JSON$place$place_type
tweets[j,7]<-JSON$place$full_name
tweets[j,8]<-JSON$user$lang
tweets[j,9]<-JSON$text
}
}
}
AFINN <- read.table("AFINN-111.txt", header=FALSE, sep="\t",  quote='', comment='',colClasses = c("character", "numeric"))
AFINN[,2]<-as.integer(AFINN[,2])
statedata <- read.csv("statepopDMA.csv", colClasses = "character")
sentiment<-function(text)
{
s<-data.frame(strsplit(as.character(text)," "))
x<-merge(s, AFINN, by.x=names(s),by.y='V1', all.x=FALSE)
sum(x$V2, na.rm=TRUE)
}
tweets$scores<-vapply(tweets[,'tweet'],sentiment, FUN.VALUE=integer(1))
alpha=.1
test<-select(inner_join(statedata,tweets,by=c("CityState"="place")),CityState,pop, scores, longitude,latitude)
test<-mutate(test,scorewt=scores*alpha)
#x<-model.matrix(~.+0, data=select(test,longitude,latitude,scorewt))
x<-select(test,longitude,latitude,scorewt)
y<-kmeans(x,30, nstart=25)
xclust<-data.frame(y$cluster,test)
xclust<-group_by(xclust,y.cluster)
xclustsum<-summarize(xclust,sum(scorewt),var(scorewt),n())
xclustsumcenter<-cbind(y$centers,xclustsum)
head(arrange(xclustsumcenter,longitude,latitude))
usa<-map_data("county")
#canmex<-filter(map_data("world"),region=="Canada"|region=="Mexico")
dfx<-data.frame(x)
ggplot(dfx, aes(dfx$latitude,dfx$longitude)) +
geom_polygon(data=usa, aes(long, lat, group=group),
colour="black",
alpha=.9) +
#geom_polygon(data=canmex, aes(long, lat, group=group),
#             colour="black",
#             alpha=.9) +
#scale_colour_gradientn(colours=rainbow(60)) +
geom_point(colour="green", alpha=.05, size=1) +
#geom_point(data=xclustsumcenter, aes(V4,V3), colour="white",size=10, alpha=.5) +
#geom_point(colour="green", alpha=.02, size=.5) +
xlim(-130, -60) + ylim(20, 52)
#tweets<-tweets[!duplicated(tweets[,9]),]
tweets<-(tweets[,1:9])
colnames<-c("V1","user","date","latitude","longitude","placetype","place","lang","tweet")
colnames(tweets)<-colnames
con <- dbConnect(MySQL(),
user = 'ehullander',
password = 'plazmajaz',
host = 'mydbehullander.c2hqmnrywoe9.us-west-2.rds.amazonaws.com',
dbname='TwitterStream')
dbWriteTable(conn = con, name = 'tweets', value = tweets, append=TRUE)
dbDisconnect(con)
setwd("C:/Users/Eric/Desktop/Learning/Python/Twitterstream/Twitterstream/MoodMap")
library(ROAuth)
library(streamR)
library(RJSONIO)
library(RMySQL)
library(ggplot2)
library(dplyr)
if(!file.exists('myEnvironment.RData'))
{
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "http://api.twitter.com/oauth/authorize"
consumerKey <- "8awxQDQEoJJzeRC6QGoCwnyqz"
consumerSecret <- "phgdvkUSZ6T1WSHF2XIwjrSvSGVdtRlqUkTOxwtMaPwKLGdedA"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
save.image("myEnvironment.RData")
} else {load('myEnvironment.RData')}
tweets<-data.frame()
temp<-filterStream(file="",
locations=c(-125.0011, 24.9493, -66.9326, 49.5904),
timeout=60,
oauth=my_oauth)
j=0
L=length(temp)
for (i in 1:L)
{
if (isValidJSON(I(temp[i]))==TRUE)
{
j=j+1
JSON<-fromJSON(temp[i])
if(!is.null(JSON$text)&!is.null(JSON$place$full_name))
{
tweets[j,1]<-JSON$id_str
tweets[j,2]<-JSON$user$screen_name
tweets[j,3]<-as.character(strptime(paste(substr(JSON$created_at, 5,10),
substr(JSON$created_at, 27,30),
substr(JSON$created_at, 12,19)),
"%b %d %Y %H:%M:%S"))
tweets[j,4]<-JSON$place$bounding_box$coordinates[[1]][[1]][2]
tweets[j,5]<-JSON$place$bounding_box$coordinates[[1]][[1]][1]
tweets[j,6]<-JSON$place$place_type
tweets[j,7]<-JSON$place$full_name
tweets[j,8]<-JSON$user$lang
tweets[j,9]<-JSON$text
}
}
}
AFINN <- read.table("AFINN-111.txt", header=FALSE, sep="\t",  quote='', comment='',colClasses = c("character", "numeric"))
AFINN[,2]<-as.integer(AFINN[,2])
statedata <- read.csv("statepopDMA.csv", colClasses = "character")
sentiment<-function(text)
{
s<-data.frame(strsplit(as.character(text)," "))
x<-merge(s, AFINN, by.x=names(s),by.y='V1', all.x=FALSE)
sum(x$V2, na.rm=TRUE)
}
tweets$scores<-vapply(tweets[,'tweet'],sentiment, FUN.VALUE=integer(1))
alpha=.1
test<-select(inner_join(statedata,tweets,by=c("CityState"="place")),CityState,pop, scores, longitude,latitude)
test<-mutate(test,scorewt=scores*alpha)
#x<-model.matrix(~.+0, data=select(test,longitude,latitude,scorewt))
x<-select(test,longitude,latitude,scorewt)
y<-kmeans(x,30, nstart=25)
xclust<-data.frame(y$cluster,test)
xclust<-group_by(xclust,y.cluster)
xclustsum<-summarize(xclust,sum(scorewt),var(scorewt),n())
xclustsumcenter<-cbind(y$centers,xclustsum)
head(arrange(xclustsumcenter,longitude,latitude))
usa<-map_data("county")
#canmex<-filter(map_data("world"),region=="Canada"|region=="Mexico")
dfx<-data.frame(x)
ggplot(dfx, aes(dfx$latitude,dfx$longitude)) +
geom_polygon(data=usa, aes(long, lat, group=group),
colour="black",
alpha=.9) +
#geom_polygon(data=canmex, aes(long, lat, group=group),
#             colour="black",
#             alpha=.9) +
#scale_colour_gradientn(colours=rainbow(60)) +
geom_point(colour="green", alpha=.05, size=1) +
#geom_point(data=xclustsumcenter, aes(V4,V3), colour="white",size=10, alpha=.5) +
#geom_point(colour="green", alpha=.02, size=.5) +
xlim(-130, -60) + ylim(20, 52)
#tweets<-tweets[!duplicated(tweets[,9]),]
tweets<-(tweets[,1:9])
colnames<-c("V1","user","date","latitude","longitude","placetype","place","lang","tweet")
colnames(tweets)<-colnames
con <- dbConnect(MySQL(),
user = 'ehullander',
password = 'plazmajaz',
host = 'mydbehullander.c2hqmnrywoe9.us-west-2.rds.amazonaws.com',
dbname='TwitterStream')
dbWriteTable(conn = con, name = 'tweets', value = tweets, append=TRUE)
dbDisconnect(con)
blob<-dbGetQuery(con, "SELECT * FROM TwitterStream.tweets WHERE tweets.tweet LIKE '%beard%'")
con <- dbConnect(MySQL(),
user = 'ehullander',
password = 'plazmajaz',
host = 'mydbehullander.c2hqmnrywoe9.us-west-2.rds.amazonaws.com',
dbname='TwitterStream')
blob<-dbGetQuery(con, "SELECT * FROM TwitterStream.tweets WHERE tweets.tweet LIKE '%beard%'")
bob$tweet
blob$tweet
blob<-dbGetQuery(con, "SELECT * FROM TwitterStream.tweets WHERE tweets.tweet LIKE '%boobs%'")
blob$tweet
blob<-dbGetQuery(con, "SELECT * FROM TwitterStream.tweets WHERE tweets.tweet LIKE '%obama%'")
blob$tweet
blob<-dbGetQuery(con, "SELECT * FROM TwitterStream.tweets WHERE tweets.tweet LIKE '%sanders%'")
blob$tweet
blob<-dbGetQuery(con, "SELECT * FROM TwitterStream.tweets WHERE tweets.tweet LIKE '%#sanders%'")
blob$tweet
blob<-dbGetQuery(con, "SELECT * FROM TwitterStream.tweets WHERE tweets.tweet LIKE '%#BecauseBaconator%'")
blob<-dbGetQuery(con, "SELECT * FROM TwitterStream.tweets WHERE tweets.tweet LIKE '%#sanders%'")
blob$place
blob<-dbGetQuery(con, "SELECT * FROM TwitterStream.tweets WHERE tweets.tweet LIKE '%sanders%'")
blob$place
dfx<-dbGetQuery(con, "SELECT * FROM TwitterStream.tweets WHERE tweets.tweet LIKE '%sanders%'")
ggplot(dfx, aes(dfx$latitude,dfx$longitude)) +
geom_polygon(data=usa, aes(long, lat, group=group),
colour="black",
alpha=.9) +
#geom_polygon(data=canmex, aes(long, lat, group=group),
#             colour="black",
#             alpha=.9) +
#scale_colour_gradientn(colours=rainbow(60)) +
geom_point(colour="green", alpha=.05, size=1) +
#geom_point(data=xclustsumcenter, aes(V4,V3), colour="white",size=10, alpha=.5) +
#geom_point(colour="green", alpha=.02, size=.5) +
xlim(-130, -60) + ylim(20, 52)
ggplot(dfx, aes(dfx$latitude,dfx$longitude)) +
geom_polygon(data=usa, aes(long, lat, group=group),
colour="black",
alpha=.9) +
#geom_polygon(data=canmex, aes(long, lat, group=group),
#             colour="black",
#             alpha=.9) +
#scale_colour_gradientn(colours=rainbow(60)) +
geom_point(colour="green", alpha=1, size=1) +
#geom_point(data=xclustsumcenter, aes(V4,V3), colour="white",size=10, alpha=.5) +
#geom_point(colour="green", alpha=.02, size=.5) +
xlim(-130, -60) + ylim(20, 52)
ggplot(dfx, aes(dfx$latitude,dfx$longitude)) +
geom_polygon(data=usa, aes(long, lat, group=group),
colour="black",
alpha=.9) +
#geom_polygon(data=canmex, aes(long, lat, group=group),
#             colour="black",
#             alpha=.9) +
#scale_colour_gradientn(colours=rainbow(60)) +
geom_point(colour="green", alpha=1, size=1) +
#geom_point(data=xclustsumcenter, aes(V4,V3), colour="white",size=10, alpha=.5) +
#geom_point(colour="green", alpha=.02, size=.5) +
xlim(-130, -60) + ylim(20, 52)
dfx
ggplot(dfx, aes(dfx$latitude,dfx$longitude)) +
geom_polygon(data=usa, aes(long, lat, group=group),
colour="black",
alpha=.9) +
#geom_polygon(data=canmex, aes(long, lat, group=group),
#             colour="black",
#             alpha=.9) +
#scale_colour_gradientn(colours=rainbow(60)) +
geom_point(colour="green", alpha=1, size=10) +
#geom_point(data=xclustsumcenter, aes(V4,V3), colour="white",size=10, alpha=.5) +
#geom_point(colour="green", alpha=.02, size=.5) +
#xlim(-130, -60) + ylim(20, 52)
ggplot(dfx, aes(dfx$latitude,dfx$longitude)) +
geom_polygon(data=usa, aes(long, lat, group=group),
colour="black",
alpha=.9) +
#geom_polygon(data=canmex, aes(long, lat, group=group),
#             colour="black",
#             alpha=.9) +
#scale_colour_gradientn(colours=rainbow(60)) +
geom_point(colour="green", alpha=1, size=10)# +
#geom_point(data=xclustsumcenter, aes(V4,V3), colour="white",size=10, alpha=.5) +
#geom_point(colour="green", alpha=.02, size=.5) +
#xlim(-130, -60) + ylim(20, 52)
ggplot(dfx, aes(dfx$longitude,dfx$latitude)) +
geom_polygon(data=usa, aes(long, lat, group=group),
colour="black",
alpha=.9) +
#geom_polygon(data=canmex, aes(long, lat, group=group),
#             colour="black",
#             alpha=.9) +
#scale_colour_gradientn(colours=rainbow(60)) +
geom_point(colour="green", alpha=1, size=1) +
#geom_point(data=xclustsumcenter, aes(V4,V3), colour="white",size=10, alpha=.5) +
#geom_point(colour="green", alpha=.02, size=.5) +
xlim(-130, -60) + ylim(20, 52)
ggplot(dfx, aes(dfx$longitude,dfx$latitude)) +
geom_polygon(data=usa, aes(long, lat, group=group),
colour="black",
alpha=.9) +
#geom_polygon(data=canmex, aes(long, lat, group=group),
#             colour="black",
#             alpha=.9) +
#scale_colour_gradientn(colours=rainbow(60)) +
geom_point(colour="green", alpha=.2, size=3) +
#geom_point(data=xclustsumcenter, aes(V4,V3), colour="white",size=10, alpha=.5) +
#geom_point(colour="green", alpha=.02, size=.5) +
xlim(-130, -60) + ylim(20, 52)
ggplot(dfx, aes(dfx$longitude,dfx$latitude)) +
geom_polygon(data=usa, aes(long, lat, group=group),
colour="black",
alpha=.9) +
#geom_polygon(data=canmex, aes(long, lat, group=group),
#             colour="black",
#             alpha=.9) +
#scale_colour_gradientn(colours=rainbow(60)) +
geom_point(colour="green", alpha=.5, size=3) +
#geom_point(data=xclustsumcenter, aes(V4,V3), colour="white",size=10, alpha=.5) +
#geom_point(colour="green", alpha=.02, size=.5) +
xlim(-130, -60) + ylim(20, 52)
term<-"beards"
SQL<-paste("SELECT * FROM TwitterStream.tweets WHERE tweets.tweet LIKE '%",term,"%",sep="")
SQL
SQL<-paste("SELECT * FROM TwitterStream.tweets WHERE tweets.tweet LIKE '%",term,"%'",sep="")
SQL
plotme<-function(term)
{
SQL<-paste("SELECT * FROM TwitterStream.tweets WHERE tweets.tweet LIKE '%",term,"%'",sep="")
dfx<-dbGetQuery(con,SQL)
ggplot(dfx, aes(dfx$longitude,dfx$latitude)) +
geom_polygon(data=usa, aes(long, lat, group=group),
colour="black",
alpha=.9) +
#geom_polygon(data=canmex, aes(long, lat, group=group),
#             colour="black",
#             alpha=.9) +
#scale_colour_gradientn(colours=rainbow(60)) +
geom_point(colour="green", alpha=.5, size=3) +
#geom_point(data=xclustsumcenter, aes(V4,V3), colour="white",size=10, alpha=.5) +
#geom_point(colour="green", alpha=.02, size=.5) +
xlim(-130, -60) + ylim(20, 52)
}
plotme("sanders")
plotme("beards")
plotme("sanders")
plotme<-function(term)
{
SQL<-paste("SELECT * FROM TwitterStream.tweets WHERE tweets.tweet LIKE '%",term,"%'",sep="")
dfx<-dbGetQuery(con,SQL)
ggplot(dfx, aes(dfx$longitude,dfx$latitude)) +
geom_polygon(data=usa, aes(long, lat, group=group),
colour="black",
alpha=.9) +
#geom_polygon(data=canmex, aes(long, lat, group=group),
#             colour="black",
#             alpha=.9) +
#scale_colour_gradientn(colours=rainbow(60)) +
geom_point(colour="green", alpha=.5, size=3) +
#geom_point(data=xclustsumcenter, aes(V4,V3), colour="white",size=10, alpha=.5) +
#geom_point(colour="green", alpha=.02, size=.5) +
xlim(-130, -60) + ylim(20, 52)
dfx
}
plotme<-function(term)
{
SQL<-paste("SELECT * FROM TwitterStream.tweets WHERE tweets.tweet LIKE '%",term,"%'",sep="")
dfx<-dbGetQuery(con,SQL)
ggplot(dfx, aes(dfx$longitude,dfx$latitude)) +
geom_polygon(data=usa, aes(long, lat, group=group),
colour="black",
alpha=.9) +
#geom_polygon(data=canmex, aes(long, lat, group=group),
#             colour="black",
#             alpha=.9) +
#scale_colour_gradientn(colours=rainbow(60)) +
geom_point(colour="green", alpha=.5, size=3) +
#geom_point(data=xclustsumcenter, aes(V4,V3), colour="white",size=10, alpha=.5) +
#geom_point(colour="green", alpha=.02, size=.5) +
xlim(-130, -60) + ylim(20, 52)
dfx
}
plotme("sanders")
sanders<-plotme("sanders")
